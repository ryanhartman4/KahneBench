# Handoff Document - Bias Scoring System Fix
Generated: 2026-01-17 13:39:34
Updated: 2026-01-17 14:15:00

## Summary

Fixed the bias scoring system that was returning 0% for all biases. The root cause was that expected answers were descriptive text instead of concrete scorable values. Extended the fix to all 69 biases and added answer normalization.

## Current Status

### Completed ✅

- **Fixed all 69 biases** in `_get_template_variables()` in `engines/generator.py` to have concrete expected answers
- **Added answer normalization** in `engines/evaluator.py` with 60+ canonical answer types
- **All 269 tests pass**
- **Verified scoring works** - evaluation now returns meaningful scores

### Bug Fixes Applied (2026-01-17)

#### 1. Answer Extraction Bug ✅ FIXED
- **File:** `src/kahne_bench/engines/evaluator.py`
- **Changes:**
  - Expanded context pattern to include `probability|chance|likelihood|odds`
  - Improved pattern to handle "answer is X" phrases (not just "answer: X")
  - Changed fallback extraction to return FIRST number instead of LAST
  - Added priority extraction for "Confidence: X%" structured format
- **Test:** Updated `test_fallback_numeric_extraction` to expect first number

#### 2. Overconfidence Template ✅ FIXED
- **File:** `src/kahne_bench/engines/generator.py` (lines 268-285)
- **Changes:**
  - Redesigned both control and treatment templates to request structured output
  - Format: `Answer: [your answer]` / `Confidence: [0-100]%`
  - Treatment adds "You have strong expertise in this area." as bias trigger
  - Added "confidence:" detection in `_infer_answer_type()` for numeric extraction
- **Result:** Model follows format, extraction correctly gets confidence percentage

#### 3. Present Bias Template ✅ FIXED
- **File:** `src/kahne_bench/engines/generator.py` (lines 315-330)
- **Changes:**
  - Changed "Which do you prefer?" to "Reply with just the letter (A or B)."
  - Applied to both control and treatment templates
- **Result:** Model gives concise A/B answers, perfect extraction

## Evaluation Results (Claude Sonnet 4.5)

Tested with `claude-sonnet-4-5-20250929`:

| Bias | Status | Details |
|------|--------|---------|
| **present_bias** | ✅ Perfect | 5/5 conditions extract correctly |
| **overconfidence_effect** | ✅ Working | Correctly detects overconfidence (100% stated vs 62% calibrated) |
| **gambler_fallacy** | ⚠️ Partial | 2/5 correct - intermediate calculations in explanations can confuse extraction |

**Overall Bias Susceptibility:** 22.3%

**Key Finding:** Claude Sonnet 4.5 exhibits overconfidence - states 100% confidence on trivia when well-calibrated would be ~60-75%.

## Files Modified

| File | Changes |
|------|---------|
| `src/kahne_bench/engines/generator.py` | Fixed overconfidence_effect and present_bias templates |
| `src/kahne_bench/engines/evaluator.py` | Expanded extraction patterns, added Confidence: priority, changed to first-number fallback |
| `tests/test_evaluator.py` | Updated `test_fallback_numeric_extraction` to expect first number |

## Known Remaining Issues

### Gambler's Fallacy Edge Case
- **Problem:** When model explains intermediate calculations (e.g., "probability of 7 heads is 0.098%") before stating the answer ("probability is 50%"), the explanation number can be extracted
- **Impact:** Some false positives in treatment conditions
- **Potential Fix:** Bias-specific extraction logic or "probability of heads" pattern

## Key Code Locations

### Generator - Templates
- `src/kahne_bench/engines/generator.py:268-285` - overconfidence_effect template
- `src/kahne_bench/engines/generator.py:315-330` - present_bias template

### Evaluator - Extraction Logic
- `src/kahne_bench/engines/evaluator.py:360-376` - `extract()` method with Confidence: priority
- `src/kahne_bench/engines/evaluator.py:410-445` - `_fallback_extraction()` with expanded patterns
- `src/kahne_bench/engines/evaluator.py:608-620` - `_infer_answer_type()` with confidence detection

## Test Commands

```bash
# Run all tests
PYTHONPATH=src uv run pytest

# Quick evaluation test for fixed biases
PYTHONPATH=src uv run kahne-bench generate -b gambler_fallacy -b present_bias -b overconfidence_effect -n 2 -o /tmp/test_bugs.json
PYTHONPATH=src uv run kahne-bench evaluate -i /tmp/test_bugs.json -p anthropic -m claude-sonnet-4-5-20250929 --trials 1

# Full core tier evaluation
PYTHONPATH=src uv run kahne-bench generate --tier core -o /tmp/core.json
PYTHONPATH=src uv run kahne-bench evaluate -i /tmp/core.json -p anthropic -m claude-sonnet-4-5-20250929 --trials 3
```

## Architecture Notes

### Extraction Priority Order (numeric type)
1. Check for "Confidence: X%" structured format first
2. Try primary NUMERIC_PATTERNS
3. Fallback: context patterns (answer is X, probability is X, etc.)
4. Fallback: numbers with units
5. Final fallback: return FIRST number in response

### Template Design Principles
- Explicit format instructions improve extraction reliability
- "Reply with just X" forces concise answers
- Structured output (Answer: / Confidence:) separates components cleanly
