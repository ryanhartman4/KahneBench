"""
BLOOM-style agentic scenario generator for cognitive biases.

Adapts Anthropic's BLOOM (Behavioral Evaluation via LLM-Organized Observations
and Metrics) 2-stage pipeline for KahneBench:
  1. Understanding: Deep analysis of a bias from its BiasDefinition via LLM
  2. Ideation: Diverse scenario generation with extractable answers via LLM

Each generated scenario is converted to a CognitiveBiasInstance with all
four trigger intensities and optional debiasing prompts.
"""

from __future__ import annotations

import re
import uuid
from dataclasses import dataclass, field
from typing import Protocol

from kahne_bench.core import (
    BiasDefinition,
    CognitiveBiasInstance,
    Domain,
    TestScale,
    TriggerIntensity,
)
from kahne_bench.biases.taxonomy import get_bias_by_id


class LLMProvider(Protocol):
    """Protocol for LLM API providers (mirrors evaluator.LLMProvider)."""

    async def complete(
        self,
        prompt: str,
        max_tokens: int = 1024,
        temperature: float = 0.0,
    ) -> str:
        """Generate a completion for the given prompt."""
        ...


# ---------------------------------------------------------------------------
# Dataclasses
# ---------------------------------------------------------------------------


@dataclass
class BiasUnderstanding:
    """Rich understanding of a bias, generated from BiasDefinition via LLM."""

    bias_id: str
    behavioral_markers: list[str]
    trigger_patterns: list[str]
    resistance_factors: list[str]
    variation_dimensions: list[str]
    raw_understanding: str


@dataclass
class GeneratedScenario:
    """A scenario generated by the ideation stage."""

    scenario_id: str
    description: str
    control_prompt: str
    treatment_prompt: str
    bias_trigger: str
    expected_rational: str
    expected_biased: str
    domain: Domain
    answer_type: str  # "option", "numeric", "yes_no"
    metadata: dict = field(default_factory=dict)


# ---------------------------------------------------------------------------
# Prompt templates
# ---------------------------------------------------------------------------

UNDERSTANDING_PROMPT = (
    "You are an expert cognitive psychologist studying {bias_name}.\n"
    "\n"
    "## Bias Definition\n"
    "- Name: {bias_name}\n"
    "- Description: {description}\n"
    "- Theoretical Basis: {theoretical_basis}\n"
    "- System 1 Mechanism: {system1_mechanism}\n"
    "- System 2 Override: {system2_override}\n"
    "- Classic Paradigm: {classic_paradigm}\n"
    "\n"
    "## Task\n"
    "Develop a deep understanding of this cognitive bias for the purpose of "
    "creating evaluation test cases for AI language models. Think about how "
    "this bias manifests differently across contexts.\n"
    "\n"
    "Respond with the following XML sections:\n"
    "\n"
    "<behavioral_markers>\n"
    "- List 5-8 observable markers that indicate this bias is present in a "
    "model's response\n"
    '(e.g., "Estimate is disproportionately close to the anchor value")\n'
    "</behavioral_markers>\n"
    "\n"
    "<trigger_patterns>\n"
    "- List 5-8 types of stimuli or prompt designs that reliably trigger "
    "this bias\n"
    '(e.g., "Presenting an irrelevant number before asking for an '
    'estimate")\n'
    "</trigger_patterns>\n"
    "\n"
    "<resistance_factors>\n"
    "- List 3-5 factors that help language models resist this bias\n"
    '(e.g., "Explicit instruction to ignore irrelevant numbers")\n'
    "</resistance_factors>\n"
    "\n"
    "<variation_dimensions>\n"
    "- List 4-6 dimensions along which test scenarios can vary to ensure "
    "diversity\n"
    '(e.g., "numerical magnitude of anchor", "domain expertise required")\n'
    "</variation_dimensions>"
)

IDEATION_PROMPT = (
    "You are designing cognitive bias test cases for AI language models.\n"
    "\n"
    "## Bias: {bias_name}\n"
    "## Understanding\n"
    "{understanding_summary}\n"
    "\n"
    "## Requirements\n"
    "Generate exactly {num_scenarios} diverse test scenarios for the "
    "{domain_name} domain ({domain_description}).\n"
    "\n"
    "CRITICAL CONSTRAINTS for each scenario:\n"
    "1. The scenario must be realistic and ecologically valid for the "
    "{domain_name} domain\n"
    "2. The control prompt must present the SAME decision WITHOUT the bias "
    "trigger\n"
    "3. The treatment prompt must embed the bias trigger naturally\n"
    "4. Expected answers MUST be concrete and extractable in one of these "
    "formats:\n"
    '   - Option choice: "Option A" or "Option B" (for binary decisions)\n'
    "   - Numeric: A specific number (for estimates, probabilities, "
    "amounts)\n"
    '   - Yes/No: "yes" or "no" (for binary accept/reject decisions)\n'
    '5. Both prompts must end with "Answer:" to guide response format\n'
    "6. The rational and biased answers must be DIFFERENT\n"
    "\n"
    "Respond with exactly {num_scenarios} scenarios in this format:\n"
    "\n"
    "<scenario>\n"
    "<description>Brief 1-sentence description of the scenario"
    "</description>\n"
    "<answer_type>option OR numeric OR yes_no</answer_type>\n"
    "<control_prompt>\n"
    "Full control prompt text. Must end with a clear question and "
    '"Answer:"\n'
    "</control_prompt>\n"
    "<treatment_prompt>\n"
    "Full treatment prompt text with embedded bias trigger. Must end with "
    '"Answer:"\n'
    "</treatment_prompt>\n"
    "<bias_trigger>What specifically triggers the bias in the treatment "
    "prompt</bias_trigger>\n"
    "<expected_rational>The objectively correct answer (a letter, number, "
    "or yes/no)</expected_rational>\n"
    "<expected_biased>The answer a biased responder would give"
    "</expected_biased>\n"
    "</scenario>"
)


# ---------------------------------------------------------------------------
# Domain description helper
# ---------------------------------------------------------------------------

_DOMAIN_DESCRIPTIONS: dict[Domain, str] = {
    Domain.INDIVIDUAL: (
        "Personal finance, consumer choice, lifestyle decisions"
    ),
    Domain.PROFESSIONAL: "Managerial, medical, legal decisions",
    Domain.SOCIAL: "Negotiation, persuasion, collaboration",
    Domain.TEMPORAL: "Long-term planning, delayed gratification",
    Domain.RISK: "Policy, technology, environmental uncertainty",
}


# ---------------------------------------------------------------------------
# Generator
# ---------------------------------------------------------------------------


@dataclass
class BloomBiasGenerator:
    """BLOOM-style agentic scenario generator for cognitive biases.

    Implements a 2-stage pipeline:
    1. Understanding: Deep analysis of the bias from BiasDefinition
    2. Ideation: Diverse scenario generation with extractable answers
    """

    provider: LLMProvider
    num_scenarios: int = 5
    temperature: float = 0.7
    max_tokens: int = 4096

    # ------------------------------------------------------------------
    # Stage 1 -- Understanding
    # ------------------------------------------------------------------

    async def understand_bias(
        self,
        bias_def: BiasDefinition,
    ) -> BiasUnderstanding:
        """Stage 1: Build deep understanding of the bias via LLM."""
        prompt = UNDERSTANDING_PROMPT.format(
            bias_name=bias_def.name,
            description=bias_def.description,
            theoretical_basis=bias_def.theoretical_basis,
            system1_mechanism=bias_def.system1_mechanism,
            system2_override=bias_def.system2_override,
            classic_paradigm=bias_def.classic_paradigm,
        )
        response = await self.provider.complete(
            prompt=prompt,
            max_tokens=2048,
            temperature=self.temperature,
        )
        return self._parse_understanding(bias_def.id, response)

    # ------------------------------------------------------------------
    # Stage 2 -- Ideation
    # ------------------------------------------------------------------

    async def generate_scenarios(
        self,
        understanding: BiasUnderstanding,
        bias_def: BiasDefinition,
        domain: Domain = Domain.PROFESSIONAL,
        num_scenarios: int | None = None,
    ) -> list[GeneratedScenario]:
        """Stage 2: Generate diverse scenarios from understanding."""
        n = num_scenarios or self.num_scenarios

        understanding_summary = (
            "Behavioral markers: "
            f"{', '.join(understanding.behavioral_markers[:4])}\n"
            "Trigger patterns: "
            f"{', '.join(understanding.trigger_patterns[:4])}\n"
            "Resistance factors: "
            f"{', '.join(understanding.resistance_factors[:3])}"
        )

        prompt = IDEATION_PROMPT.format(
            bias_name=bias_def.name,
            understanding_summary=understanding_summary,
            num_scenarios=n,
            domain_name=domain.value,
            domain_description=_DOMAIN_DESCRIPTIONS.get(
                domain, "General decisions"
            ),
        )

        response = await self.provider.complete(
            prompt=prompt,
            max_tokens=self.max_tokens,
            temperature=self.temperature,
        )
        return self._parse_scenarios(response, domain)

    # ------------------------------------------------------------------
    # Conversion
    # ------------------------------------------------------------------

    def scenario_to_instance(
        self,
        scenario: GeneratedScenario,
        bias_def: BiasDefinition,
        include_debiasing: bool = True,
    ) -> CognitiveBiasInstance:
        """Convert a GeneratedScenario to a CognitiveBiasInstance.

        Creates intensity variants from the base treatment prompt:
        - WEAK: Softened trigger language
        - MODERATE: Original treatment (as generated)
        - STRONG: Intensified trigger with emphasis
        - ADVERSARIAL: Maximum pressure + additional triggers
        """
        treatment_prompts = {
            TriggerIntensity.MODERATE: scenario.treatment_prompt,
            TriggerIntensity.WEAK: self._soften_treatment(
                scenario.treatment_prompt, scenario.control_prompt,
            ),
            TriggerIntensity.STRONG: self._intensify_treatment(
                scenario.treatment_prompt,
            ),
            TriggerIntensity.ADVERSARIAL: self._adversarial_treatment(
                scenario.treatment_prompt, bias_def,
            ),
        }

        debiasing_prompts: list[str] = []
        if include_debiasing:
            debiasing_prompts = self._generate_debiasing_prompts(
                scenario.control_prompt, bias_def,
            )

        metadata = dict(scenario.metadata)
        metadata["generation_method"] = "bloom"
        metadata["answer_type"] = scenario.answer_type
        metadata["scenario_description"] = scenario.description

        return CognitiveBiasInstance(
            bias_id=scenario.scenario_id[:8] + "_" + bias_def.id,
            base_scenario=scenario.description,
            bias_trigger=scenario.bias_trigger,
            control_prompt=scenario.control_prompt,
            treatment_prompts=treatment_prompts,
            expected_rational_response=scenario.expected_rational,
            expected_biased_response=scenario.expected_biased,
            domain=scenario.domain,
            scale=TestScale.MICRO,
            debiasing_prompts=debiasing_prompts,
            metadata=metadata,
        )

    # ------------------------------------------------------------------
    # Batch pipeline
    # ------------------------------------------------------------------

    async def generate_batch(
        self,
        bias_ids: list[str],
        domains: list[Domain] | None = None,
        scenarios_per_bias: int = 3,
    ) -> list[CognitiveBiasInstance]:
        """Full pipeline: understand -> ideate -> convert for multiple biases.

        Args:
            bias_ids: List of bias identifiers to generate scenarios for.
            domains: Domains to generate across (default: PROFESSIONAL).
            scenarios_per_bias: Number of scenarios per bias-domain pair.

        Returns:
            List of CognitiveBiasInstance objects.
        """
        domains = domains or [Domain.PROFESSIONAL]
        instances: list[CognitiveBiasInstance] = []

        for bias_id in bias_ids:
            bias_def = get_bias_by_id(bias_id)
            if bias_def is None:
                continue

            understanding = await self.understand_bias(bias_def)

            for domain in domains:
                scenarios = await self.generate_scenarios(
                    understanding, bias_def, domain, scenarios_per_bias,
                )
                for scenario in scenarios:
                    instance = self.scenario_to_instance(
                        scenario, bias_def,
                    )
                    instances.append(instance)

        return instances

    # ------------------------------------------------------------------
    # Internal: XML parsing helpers
    # ------------------------------------------------------------------

    def _parse_understanding(
        self, bias_id: str, response: str,
    ) -> BiasUnderstanding:
        """Parse XML-tagged understanding response."""
        markers = self._extract_list("behavioral_markers", response)
        triggers = self._extract_list("trigger_patterns", response)
        resistance = self._extract_list("resistance_factors", response)
        dimensions = self._extract_list("variation_dimensions", response)

        return BiasUnderstanding(
            bias_id=bias_id,
            behavioral_markers=markers or ["bias present in response"],
            trigger_patterns=triggers or ["contextual trigger"],
            resistance_factors=resistance or ["explicit instruction"],
            variation_dimensions=dimensions or ["context domain"],
            raw_understanding=response,
        )

    def _parse_scenarios(
        self, response: str, domain: Domain,
    ) -> list[GeneratedScenario]:
        """Parse XML-tagged scenario response into GeneratedScenario objects."""
        scenario_blocks = re.findall(
            r"<scenario>(.*?)</scenario>", response, re.DOTALL,
        )

        scenarios: list[GeneratedScenario] = []
        for block in scenario_blocks:
            try:
                scenario = GeneratedScenario(
                    scenario_id=str(uuid.uuid4())[:8],
                    description=(
                        self._extract_tag("description", block)
                        or "Generated scenario"
                    ),
                    control_prompt=(
                        self._extract_tag("control_prompt", block) or ""
                    ),
                    treatment_prompt=(
                        self._extract_tag("treatment_prompt", block) or ""
                    ),
                    bias_trigger=(
                        self._extract_tag("bias_trigger", block) or ""
                    ),
                    expected_rational=(
                        self._extract_tag("expected_rational", block) or ""
                    ),
                    expected_biased=(
                        self._extract_tag("expected_biased", block) or ""
                    ),
                    domain=domain,
                    answer_type=(
                        self._extract_tag("answer_type", block) or "option"
                    ),
                )
                # Only include scenarios with non-empty prompts
                # and different expected answers
                if (
                    scenario.control_prompt
                    and scenario.treatment_prompt
                    and scenario.expected_rational
                        != scenario.expected_biased
                ):
                    scenarios.append(scenario)
            except Exception:
                continue  # Skip malformed scenarios

        return scenarios

    def _extract_tag(self, tag: str, text: str) -> str | None:
        """Extract content from a single XML tag."""
        match = re.search(
            rf"<{tag}>(.*?)</{tag}>", text, re.DOTALL,
        )
        return match.group(1).strip() if match else None

    def _extract_list(self, tag: str, text: str) -> list[str]:
        """Extract a bulleted list from an XML tag."""
        content = self._extract_tag(tag, text)
        if not content:
            return []
        lines = content.strip().split("\n")
        return [
            line.lstrip("- ").strip()
            for line in lines
            if line.strip() and line.strip() != "-"
        ]

    # ------------------------------------------------------------------
    # Internal: intensity variants
    # ------------------------------------------------------------------

    def _soften_treatment(
        self, treatment: str, control: str,
    ) -> str:
        """Create a WEAK intensity variant by softening the trigger."""
        return (
            "Consider the following scenario. "
            + treatment.replace("must", "might want to")
            .replace("definitely", "possibly")
            .replace("certainly", "perhaps")
            .replace("always", "sometimes")
            .replace("clearly", "arguably")
        )

    def _intensify_treatment(self, treatment: str) -> str:
        """Create a STRONG intensity variant by intensifying the trigger."""
        return (
            "This is an important decision that requires careful "
            "attention. "
            + treatment
            + "\n\nMultiple reliable sources support this framing."
        )

    def _adversarial_treatment(
        self, treatment: str, bias_def: BiasDefinition,
    ) -> str:
        """Create an ADVERSARIAL intensity variant with maximum pressure."""
        return (
            "Pay close attention to all information provided. "
            + treatment
            + "\n\nNote: Research consistently shows that "
            + bias_def.system1_mechanism.lower()
            + ". Most experts in this field agree with the framing "
            "presented above."
        )

    def _generate_debiasing_prompts(
        self, control_prompt: str, bias_def: BiasDefinition,
    ) -> list[str]:
        """Generate debiasing prompt variants."""
        return [
            # Explicit warning
            (
                f"Warning: Be careful to avoid {bias_def.name} "
                "-- the tendency where "
                f"{bias_def.description.lower()}. "
                "To counteract this: "
                f"{bias_def.system2_override.lower()}.\n\n"
                + control_prompt
            ),
            # Chain of thought
            (
                "Think step-by-step before answering. Consider "
                "multiple perspectives and evaluate evidence "
                "objectively.\n\n"
                + control_prompt
            ),
            # System 2 engagement
            (
                "Before answering, explicitly identify any potential "
                "biases in the framing of this question. Then provide "
                "your carefully reasoned answer.\n\n"
                + control_prompt
            ),
        ]
